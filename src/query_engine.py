import json
import logging
from llama_index.llms.ollama import Ollama
from llama_index.core.query_engine import CustomQueryEngine
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.response_synthesizers import BaseSynthesizer
from llama_index.core import PromptTemplate
from datetime import datetime


logger = logging.getLogger('goat_nlp.query_engine')


class GoaTAPIQueryEngine(CustomQueryEngine):
    """
    Custom query engine for the GoaT API.

    Attributes:
        retriever (BaseRetriever): The retriever used to retrieve nodes.
        response_synthesizer (BaseSynthesizer): The synthesizer used to
            generate responses.
        llm (Ollama): The language model used for completion.
        qa_prompt (PromptTemplate): The template for the QA prompt.
    """

    retriever: BaseRetriever
    response_synthesizer: BaseSynthesizer
    llm: Ollama
    qa_prompt: PromptTemplate
    question_store: dict

    def custom_query(self, query_str: str):
        """
        Custom query method.

        Args:
            query_str (str): The query string.
            entity_taxon_map (dict): The entity taxon map.

        Returns:
            str: The response generated by the language model.
        """
        nodes = self.retriever.retrieve(query_str)

        context_str = "\n\n".join([json.dumps(self.question_store[n.node.get_content()],
                                              indent=2) for n in nodes])
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        populated_prompt = self.qa_prompt.format(context_str=context_str,
                                                 query_str=query_str,
                                                 time=current_time)
        logger.info(populated_prompt)
        response = self.llm.complete(
            populated_prompt
        )
        logger.info(response)

        return str(response)
